{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f14448",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5346d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf2477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print(f'tf: {tf.__version__}, keras: {keras.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38fb67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for managing all model metadata, use neptune.ai:\n",
    "import neptune.new as neptune\n",
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
    "neptune.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258aabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import ml_utils\n",
    "import pose_utils\n",
    "from pose_utils import DEG_TO_RAD\n",
    "from pose_utils import RAD_TO_SCALED\n",
    "from pose_utils import MAX_DEPTH\n",
    "from pose_utils import METERS_TO_SCALED\n",
    "from pose_utils import INTENSITY_TO_SCALED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_data_path = '/data/all_around_zones_3500_tf_data'\n",
    "# tf_data_path = '/data/all_around_scout_4501_tf_data'\n",
    "# tf_data_path = '/data/face_to_face_zones_2500_tf_data'\n",
    "# tf_data_path = '/data/hopper_4500_tf_data'\n",
    "tf_data_path = '/data/t_formation_zones_3500_tf_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eab0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ml_utils.load_dataset(tf_data_path + '_train', compression='GZIP')\n",
    "ds_val = ml_utils.load_dataset(tf_data_path + '_val', compression='GZIP')\n",
    "ds_test = ml_utils.load_dataset(tf_data_path + '_test', compression='GZIP')\n",
    "\n",
    "n_channels = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d21ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### (optional) \n",
    "### test performance with a subset of input data \n",
    "### (instead of RGBD, try other combinations and color spaces)\n",
    "# import cv2\n",
    "# def remove_band(image, b):\n",
    "#     image = np.delete(image, b, -1)\n",
    "#     return image\n",
    "\n",
    "# def rgb_to_hsv(image):\n",
    "#     image = image.numpy() * 255.\n",
    "#     hsv = cv2.cvtColor(image.astype('uint8'), cv2.COLOR_RGB2HSV) / 255.\n",
    "#     return hsv\n",
    "\n",
    "# def rgbd_to_hsvd(image):\n",
    "#     image = image.numpy()\n",
    "#     img = image[:,:,:3] * 255.\n",
    "#     hsv = cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2HSV) / 255.\n",
    "#     image[:,:,:3] = hsv\n",
    "#     return image\n",
    "\n",
    "# def rgbd_to_hvd(image):\n",
    "#     img = image[:,:,:3].numpy() * 255.\n",
    "#     hsv = cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2HSV) / 255.\n",
    "#     hv = remove_band(hsv, 1)\n",
    "#     image = remove_band(image, 1)\n",
    "#     image[:,:,:2] = hv\n",
    "#     return image\n",
    "\n",
    "# def rgbd_to_hv(image):\n",
    "#     image = image.numpy()\n",
    "#     img = image[:,:,:3] * 255.\n",
    "#     hsv = cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2HSV) / 255.\n",
    "#     image[:,:,:3] = hsv\n",
    "#     return remove_band(image, 1)[:,:,:2]\n",
    "\n",
    "# def rgbd_to_hd(image):\n",
    "#     image = image.numpy()\n",
    "#     img = image[:,:,:3] * 255.\n",
    "#     hsv = cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2HSV) / 255.\n",
    "#     image[:,:,:3] = hsv\n",
    "#     image = remove_band(image, 1) # remove s\n",
    "#     image = remove_band(image, 1) # remove v\n",
    "#     return image\n",
    "\n",
    "# n_channels = 1\n",
    "# mapper = lambda image, label: (image[:,:,-1], label)  # only Depth\n",
    "# n_channels = 3\n",
    "# mapper = lambda image, label: (image[:,:,:3], label)  # only RGB\n",
    "# n_channels = 3\n",
    "# mapper = lambda image, label: (tf.py_function(func=remove_band, inp=[image, 1], Tout=tf.float64), label)  # only Red + Blue + Depth\n",
    "# n_channels = 2\n",
    "# mapper = lambda image, label: (tf.py_function(func=remove_band, inp=[image[:,:,:3], 1], Tout=tf.float64), label)  # only Red + Blue\n",
    "# n_channels = 3\n",
    "# mapper = lambda image, label: (tf.py_function(func=rgb_to_hsv, inp=[image[:,:,:3]], Tout=tf.float64), label)  # HSV\n",
    "# n_channels = 4\n",
    "# mapper = lambda image, label: (tf.py_function(func=rgbd_to_hsvd, inp=[image], Tout=tf.float64), label)  # HSV + Depth\n",
    "# n_channels = 3\n",
    "# mapper = lambda image, label: (tf.py_function(func=rgbd_to_hvd, inp=[image], Tout=tf.float64), label)  # only Hue and Value + Depth\n",
    "# n_channels = 2\n",
    "# mapper = lambda image, label: (tf.py_function(func=rgbd_to_hv, inp=[image], Tout=tf.float64), label)  # only Hue and Value\n",
    "# n_channels = 2\n",
    "# mapper = lambda image, label: (tf.py_function(func=rgbd_to_hd, inp=[image], Tout=tf.float64), label)  # only Hue + Depth\n",
    "# ds_train = ds_train.map(mapper)\n",
    "# ds_val = ds_val.map(mapper)\n",
    "# ds_test = ds_test.map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a67f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in ds_train.take(1):\n",
    "    pose_utils.show_rgbd(image, format='rgbd')\n",
    "    d, theta, yaw = label.numpy()\n",
    "    print(f\"raw:   d = {d:.3f} , theta = {theta:.3f}    , yaw = {yaw:.3f} \")\n",
    "    print(f\"human: d = {d / METERS_TO_SCALED:.2f} m, theta = {theta / RAD_TO_SCALED / DEG_TO_RAD:.1f} deg, yaw = {yaw / RAD_TO_SCALED / DEG_TO_RAD:.1f} deg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f23d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'ljburtz/relative-pose'\n",
    "PARAMS = {\n",
    "    'height': 120,\n",
    "    'width': 160,\n",
    "    'channels': n_channels,\n",
    "    'pool_size' : 2,\n",
    "    'patience': 4,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 300,\n",
    "    'alpha': 0.1,\n",
    "    'beta': 0.03,\n",
    "    'description': 'no preprocessing pipeline'\n",
    "}\n",
    "# TAGS = ['all_around']\n",
    "# TAGS = ['all_around_scout']\n",
    "# TAGS = ['face_to_face']\n",
    "# TAGS = ['hopper']\n",
    "TAGS = ['t_formation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4530f43",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e802f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_basic_model(input_shape, height, width, n_outputs, pool_size):\n",
    "\n",
    "    model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.experimental.preprocessing.Resizing(height, width),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(pool_size=pool_size),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(pool_size=pool_size),        \n",
    "        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(pool_size=pool_size),\n",
    "        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(pool_size=pool_size),\n",
    "        layers.Flatten(),\n",
    "\n",
    "        layers.Dense(6, activation=\"relu\"),\n",
    "        layers.Dense(24, activation=\"relu\"),\n",
    "        layers.Dense(24, activation=\"relu\"),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(n_outputs, activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c78c6d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_shape = (28, 28, 1) # for MNIST\n",
    "# input_shape = (32, 32, 3)  # for CIFAR\n",
    "input_shape = (480, 640, n_channels)\n",
    "height, width = PARAMS['height'], PARAMS['width']\n",
    "pool_size = PARAMS['pool_size']\n",
    "n_outputs = 3\n",
    "\n",
    "model = make_basic_model(input_shape, height, width, n_outputs, pool_size)\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcca27f2",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5850466",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = PARAMS['batch_size']\n",
    "buffer_size = tf.data.experimental.AUTOTUNE  # the prefetch buffer size is dynamically tuned\n",
    "\n",
    "ds_train_b = ds_train.batch(batch_size, drop_remainder=True).prefetch(buffer_size)\n",
    "ds_val_b = ds_val.batch(batch_size, drop_remainder=True).prefetch(buffer_size)\n",
    "ds_test_b = ds_test.batch(batch_size, drop_remainder=True).prefetch(buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = PARAMS['epochs']\n",
    "alpha = PARAMS['alpha']\n",
    "beta = PARAMS['beta']\n",
    "\n",
    "def pose_loss(y_true, y_pred):\n",
    "    pose_loss = \\\n",
    "        ml_utils.distance_loss(y_true, y_pred) +  \\\n",
    "        alpha * ml_utils.theta_loss(y_true, y_pred) + \\\n",
    "        beta * ml_utils.orientation_loss(y_true, y_pred)\n",
    "    return pose_loss\n",
    "\n",
    "def theta_loss(y_true, y_pred):\n",
    "    return alpha * ml_utils.theta_loss(y_true, y_pred)\n",
    "\n",
    "def orientation_loss(y_true, y_pred):\n",
    "    return beta * ml_utils.orientation_loss(y_true, y_pred)\n",
    "\n",
    "model.compile(\n",
    "    loss=pose_loss, \n",
    "    optimizer='adam', \n",
    "    metrics=[\n",
    "        ml_utils.distance_loss,     # intermediate loss, for tuning alpha and beta\n",
    "        theta_loss,                 # intermediate loss, for tuning alpha and beta\n",
    "        orientation_loss,           # intermediate loss, for tuning alpha and beta\n",
    "        ml_utils.distance_diff,     # intermediate errors: human understandable\n",
    "        ml_utils.theta_diff,        # intermediate errors: human understandable\n",
    "        ml_utils.orientation_diff,  # intermediate errors: human understandable\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb324b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS, TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e39c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a run to log all data to the neptune cloud\n",
    "run = neptune.init(project=PROJECT,\n",
    "                   tags=TAGS,\n",
    "                   source_files=['RelativePose_train.ipynb']  # upload a snapshot of the notebook\n",
    "#                    mode='debug'\n",
    "                  )\n",
    "run_id = run['sys/id'].fetch()\n",
    "print(run_id)\n",
    "run.assign({'parameters': PARAMS}, wait=True)  # synchronous call to make sure parameters are synced with the neptune server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # callback for model metadata logging\n",
    "    NeptuneCallback(run=run, base_namespace='metrics'),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        '/tmp/best_model_loss.h5', \n",
    "        save_weights_only=True,\n",
    "        save_best_only=True, \n",
    "        monitor='val_loss', \n",
    "        mode='min'\n",
    "    ),\n",
    "    # usual callbacks\n",
    "    keras.callbacks.ReduceLROnPlateau(),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "#         min_delta=0.0003,\n",
    "        mode='min', \n",
    "        patience=PARAMS['patience'], \n",
    "        verbose=1, \n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    # callback for profiling CPU/GPU utilisation\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='/tmp/profile', \n",
    "        profile_batch='5,15',\n",
    "        histogram_freq=0, \n",
    "        write_images=False\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b50486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    ds_train_b, \n",
    "    epochs=epochs, \n",
    "    validation_data=ds_val_b,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e97576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path = f\"/tmp/model_\"\n",
    "\n",
    "# save full model (e.g for resuming training later on)\n",
    "model.save(path + 'end.h5')\n",
    "\n",
    "# save model weights and architecture (e.g for inference only)\n",
    "model.save_weights(path + 'relative_pose_weights.h5')\n",
    "json_config = model.to_json()\n",
    "with open(path + 'relative_pose_config.json', 'w') as out_:\n",
    "    json.dump(json_config, out_)\n",
    "\n",
    "# log artifacts to Neptune    \n",
    "run[\"model/model_end\"].upload(path + 'end.h5')\n",
    "run['model/model_relative_pose_weights'].upload(path + \"relative_pose_weights.h5\")\n",
    "run['model/model_relative_pose_config'].upload(path + \"relative_pose_config.json\")\n",
    "\n",
    "# log additional metrics\n",
    "min_loss, min_loss_epoch, min_pdiff, min_pdiff_epoch = ml_utils.get_best_metrics(history, accuracy_metric='distance_diff')\n",
    "run['metrics/min_loss'] = min_loss\n",
    "run['metrics/min_loss_epoch'] = min_loss_epoch\n",
    "run[\"metrics/min_pdiff\"] = min_pdiff\n",
    "run['metrics/min_pdiff_epoch'] = min_pdiff_epoch\n",
    "print(run['sys/id'].fetch())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a23587",
   "metadata": {},
   "source": [
    "evaluate model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c542928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(ds_test_b)\n",
    "print(\"test loss, test metrics:\", results)\n",
    "run['test/avg_position_diff'] = results[-3]\n",
    "run['test/avg_theta_diff'] = results[-2]\n",
    "run['test/avg_orientation_diff'] = results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred = 100\n",
    "d_true, theta_true, yaw_true, d_list, theta_list, yaw_list = ml_utils.predict_and_scale(\n",
    "    model,\n",
    "    ds_test,\n",
    "    ds_test_b,\n",
    "    n_pred,\n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9faa953",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pose_utils.compare_each_output( \n",
    "    d_true, theta_true, yaw_true, \n",
    "    d_list, theta_list, yaw_list,\n",
    "    subset=50\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['test/compare_outputs'].upload(neptune.types.File.as_html(fig))  # interactive fig\n",
    "run['test/compare_outputs_png'].upload(neptune.types.File.as_image(pose_utils.plotly2array(fig)))  # static fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc13b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pose_utils.compare_optical_poses(\n",
    "    d_true, theta_true, yaw_true, \n",
    "    d_list, theta_list, yaw_list, \n",
    "    yaw_viz_offset=np.pi/2.,\n",
    "#     footprint='small_scout_1'\n",
    "#     footprint='processing_plant'\n",
    "    footprint='small_excavator_1'\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bafa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['test/compare_poses'].upload(neptune.types.File.as_html(fig))  # interactive fig\n",
    "run['test/compare_poses_png'].upload(neptune.types.File.as_image(pose_utils.plotly2array(fig)))  # static fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a91e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pose_utils.hist_errors(\n",
    "    d_true, theta_true, yaw_true, \n",
    "    d_list, theta_list, yaw_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['test/error_hist'].upload(neptune.types.File.as_image(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a1f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa8b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4132c58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf382873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb0ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
